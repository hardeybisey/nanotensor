{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed May 18 08:40:19 2022\n",
    "\n",
    "@author: MREID7\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "#Maps Users to Market or Market Group\n",
    "STR_SQL_USERS_TO_MKT_MKTGRP = '''select distinct coalesce(m.MarketName,mg.MarketGroupName) as MktOrMktGrp, u.PIN, butmomg.MarketOrMarketGroupUUID,u.UserUUID \n",
    "FROM User u\n",
    "INNER JOIN Employment e on u.UserUUID  = e.UserUUID \n",
    "INNER JOIN BusinessUnitToMarketOrMarketGroup butmomg on e.BusinessUnitUUID = butmomg.BusinessUnitUUID \n",
    "LEFT JOIN Market m on butmomg.MarketOrMarketGroupUUID = m.MarketUUID \n",
    "LEFT JOIN MarketGroup mg on butmomg.MarketOrMarketGroupUUID = mg.MarketGroupUUID \n",
    "WHERE u.Active = b'1'\n",
    "AND e.EmploymentStatusUUID = (SELECT es.EmploymentStatusUUID  from EmploymentStatus es WHERE es.Name = 'Employed')\n",
    "'''\n",
    "\n",
    "#Fast track users\n",
    "STR_SQL_FASTTRACK_USERS = '''SELECT DISTINCT \n",
    "\t  u.PIN\n",
    "\t, jrl.JobRoleName\n",
    "\t, GROUP_CONCAT(DISTINCT COALESCE(mg.MarketGroupName, m.MarketName)) AS Markets\n",
    "\t, GROUP_CONCAT(DISTINCT ljl2.Title) AS LearnerJourneys\n",
    "\t, GROUP_CONCAT(DISTINCT ljll.LearnerJourneyLevelTitle) AS FastTrackLevels\n",
    "\t, GROUP_CONCAT(DISTINCT bl.BrandName) AS Brands\n",
    "FROM UserCertificationPathFastTrackLevel ucpftl\n",
    "INNER JOIN UserCertificationPath ucp USING (UserCertificationPathUUID)\n",
    "INNER JOIN EmploymentJobRole ejr USING (EmploymentJobRoleUUID)\n",
    "INNER JOIN Employment e USING (EmploymentUUID)\n",
    "INNER JOIN BusinessUnit bu ON e.BusinessUnitUUID = bu.BusinessUnitUUID \n",
    "INNER JOIN BrandLocal bl ON bu.BrandUUID = bl.BrandUUID\n",
    "INNER JOIN User u ON e.UserUUID = u.UserUUID\n",
    "INNER JOIN BusinessUnitToMarketOrMarketGroup butmomg ON bu.BusinessUnitUUID = butmomg.BusinessUnitUUID\n",
    "INNER JOIN EmploymentJobRoleStatus ejrs USING (EmploymentJobRoleStatusUUID)\n",
    "INNER JOIN EmploymentStatus es USING (EmploymentStatusUUID)\n",
    "INNER JOIN UserStatus us ON u.UserAccountStatusUUID = us.UserStatusUUID\n",
    "INNER JOIN JobRoleLocal jrl ON ejr.JobRoleUUID = jrl.JobRoleUUID AND jrl.LanguageUUID = (SELECT LanguageUUID FROM Language WHERE LanguageName = 'English')\n",
    "INNER JOIN LearnerJourneyLevel ljl ON ucpftl.LearnerJourneyLevelUUID = ljl.LearnerJourneyLevelUUID AND ljl.IsFastTrack = 1\n",
    "INNER JOIN LearnerJourneyLevelLocal ljll ON ljl.LearnerJourneyLevelUUID = ljll.LearnerJourneyLevelUUID AND ljll.LanguageUUID = (SELECT LanguageUUID FROM Language WHERE LanguageName = 'English')\n",
    "INNER JOIN LearnerJourneyVersion ljv ON ljl.LearnerJourneyVersionUUID = ljv.LearnerJourneyVersionUUID AND ucp.LearnerJourneyUUID = ljv.LearnerJourneyUUID\n",
    "INNER JOIN LearnerJourneyLocal ljl2 ON ljv.LearnerJourneyVersionUUID = ljl2.LearnerJourneyVersionUUID AND ljl2.LanguageUUID = (SELECT LanguageUUID FROM Language WHERE LanguageName = 'English')\n",
    "LEFT JOIN MarketGroup mg ON butmomg.MarketOrMarketGroupUUID = mg.MarketGroupUUID\n",
    "LEFT JOIN Market m ON butmomg.MarketOrMarketGroupUUID = m.MarketUUID\n",
    "WHERE ejrs.Name = 'Active' AND es.Name = 'Employed' AND us.Name = 'Active' AND ucpftl.IsFastTrack = 1\n",
    "GROUP BY u.PIN, jrl.JobRoleName '''\n",
    "\n",
    "#Learner Journey Level History\n",
    "STR_SQL_JOURNEY_LEVEL_HISTORY = '''select u.PIN, cp.Name as CertPath, jr.ReferenceCode as JobRole, ujlh.StartDate, ujlh.CompletionDate, ujlh.LevelExpiryDate,ujlh.CreatedDate,ljll.LearnerJourneyLevelTitle , cs.StatusCode, ujlh.IsCurrent,cp.IsTechnical, ujlh.UserJourneyLevelHistoryUUID \n",
    "from UserJourneyLevelHistory ujlh\n",
    "inner join User u on ujlh.UserUUID = u.UserUUID \n",
    "inner join CourseStatus cs on ujlh.SuccessStatusUUID = cs.CourseStatusUUID \n",
    "inner join LearnerJourneyLevelLocal ljll on ujlh.LearnerJourneyLevelUUID = ljll.LearnerJourneyLevelUUID  and ljll.LanguageUUID = '33e5850a-473f-11e8-9661-7bf55cea83d1'\n",
    "inner join LearnerJourneyVersion ljv on ujlh.LearnerJourneyVersionUUID = ljv.LearnerJourneyVersionUUID \n",
    "inner join JobRole jr on ljv.JobRoleUUID = jr.JobRoleUUID \n",
    "inner join CertificationPath cp on ljv.CertificationPathUUID = cp.CertificationPathUUID \n",
    "left join EmploymentJobRole ejr on ujlh.UserEntityJobRoleUUID = ejr.EmploymentJobRoleUUID \n",
    "where cp.IsTechnical > 0'''\n",
    "\n",
    "#FROM EVO_FIMS_Combo_02\n",
    "STR_SQL_BUSINESS_UNITS = '''SELECT COALESCE(m.MarketName, mg.MarketGroupName) AS MarketName, but.Name as BusUnitType, bust.Name as BusUnitSubType, bus.Name as UnitStatus, CONV(bus.IsActiveStatus,2,10) AS IsActiveStatus, bu.Name as BusinessUnit, b.BrandCode,  bu.CICode, a.Town, bu.ChargingStartDate, bu.ChargingEndDate, bu.BusinessUnitUUID\n",
    "FROM BusinessUnit bu\n",
    "INNER JOIN BusinessUnitType but ON bu.BusinessUnitTypeUUID = but.BusinessUnitTypeUUID \n",
    "INNER JOIN BusinessUnitSubType bust ON bu.BusinessUnitSubTypeUUID = bust.BusinessUnitSubTypeUUID \n",
    "INNER JOIN BusinessUnitStatus bus ON bu.BusinessUnitStatusUUID = bus.BusinessUnitStatusUUID \n",
    "LEFT JOIN Address a ON bu.AddressUUID = a.AddressUUID \n",
    "LEFT JOIN Brand b ON bu.BrandUUID = b.BrandUUID \n",
    "LEFT JOIN BusinessUnitToMarketOrMarketGroup butmomg on bu.BusinessUnitUUID = butmomg.BusinessUnitUUID \n",
    "LEFT JOIN Market m on butmomg.MarketOrMarketGroupUUID = m.MarketUUID\n",
    "LEFT JOIN MarketGroup mg on butmomg.MarketOrMarketGroupUUID = mg.MarketGroupUUID'''\n",
    "\n",
    "#FROM EVO_Reporting_Extracts_05\n",
    "STR_SQL_USERS = '''SELECT u.PIN, up.FirstName, up.Surname, up.EmailAddress, CONV(u.Active,2,10) as Active, u.LastLogin, uss.Name as UserSubStatus, u.UserUUID\n",
    "FROM JLR_LMS_Reporting.User u\n",
    "INNER JOIN UserProfile up ON u.UserUUID = up.UserUUID\n",
    "INNER JOIN UserSubStatus uss ON u.UserAccountSubStatusUUID = uss.UserSubStatusUUID'''\n",
    "\n",
    "STR_SQL_EMPLOYMENT = '''SELECT ES.Name as EmpStatus, b.BrandCode, CONV(E.IsMerged,2,10) AS IsMerged, E.BusinessUnitUUID, E.UserUUID, E.EmploymentUUID, E.StartDate, E.EndDate, E.CreatedDate, E.UpdatedDate  \n",
    "FROM JLR_LMS_Reporting.Employment E\n",
    "INNER JOIN EmploymentStatus ES ON ES.EmploymentStatusUUID = E.EmploymentStatusUUID\n",
    "LEFT JOIN Brand b ON E.BrandUUID = b.BrandUUID '''\n",
    "\n",
    "\n",
    "STR_SQL_EMPLOYMENT_JOB_ROLE = '''select jr.ReferenceCode, e.EmploymentUUID, es.Name as EmpStatus, CONV(ejr.IsPrimary,2,10) AS IsPrimary, ejr.StartDate, ejr.EndDate, b.BrandCode, CONV(e.IsMerged,2,10) AS IsMerged, jr.CertificationPath, jr.CertificationPathUUID, e.BusinessUnitUUID, e.UserUUID, ejr.ManagerUUID, jr.DepartmentUUID, ejr.EmploymentJobRoleUUID, ejrs.Name EJRstatus \n",
    "FROM EmploymentJobRole ejr \n",
    "INNER JOIN Employment e ON ejr.EmploymentUUID  = e.EmploymentUUID\n",
    "INNER JOIN EmploymentStatus es ON e.EmploymentStatusUUID = es.EmploymentStatusUUID\n",
    "INNER JOIN EmploymentJobRoleStatus ejrs ON ejr.EmploymentJobRoleStatusUUID = ejrs.EmploymentJobRoleStatusUUID \n",
    "INNER JOIN JobRole jr ON ejr.JobRoleUUID = jr.JobRoleUUID\n",
    "LEFT JOIN Brand b ON e.BrandUUID = b.BrandUUID'''\n",
    "\n",
    "# STR_SQL_EMPLOYMENT_JOB_ROLE = '''select jr.ReferenceCode, es.Name as EmpStatus, CONV(ejr.IsPrimary,2,10) AS IsPrimary, ejr.StartDate, ejr.EndDate, b.BrandCode, CONV(e.IsMerged,2,10) AS IsMerged, jr.CertificationPath, jr.CertificationPathUUID, e.BusinessUnitUUID, e.UserUUID, ejr.ManagerUUID, jr.DepartmentUUID, ejr.EmploymentJobRoleUUID, ejrs.Name EJRstatus \n",
    "# FROM EmploymentJobRole ejr \n",
    "# INNER JOIN Employment e ON ejr.EmploymentUUID  = e.EmploymentUUID\n",
    "# INNER JOIN EmploymentStatus es ON e.EmploymentStatusUUID = es.EmploymentStatusUUID\n",
    "# INNER JOIN EmploymentJobRoleStatus ejrs ON ejr.EmploymentJobRoleStatusUUID = ejrs.EmploymentJobRoleStatusUUID \n",
    "# INNER JOIN JobRole jr ON ejr.JobRoleUUID = jr.JobRoleUUID\n",
    "# LEFT JOIN Brand b ON e.BrandUUID = b.BrandUUID'''\n",
    "\n",
    "STR_SQL_CERIFICATION_PATH = '''select cp.Name as CertPath, cc.CertifiedLevel as CurrentLevelName, cc.TargetLevel as TargetLevelName, cc.CertificationExpiryDate as ExpirationDate, \n",
    "CONV(cp.IsTechnical,2,10) as IsTechnical,  CONV(ucp.IsFastTrack,2,10) as IsFastTrack, ucp.LearnerJourneyUUID, ucp.EmploymentJobRoleUUID,\n",
    "ucp.UserUUID, ujlh.CompletionDate, u.PIN, cc.AssociateLevel as CurrentStudyLevel\n",
    "from Cache_Certification cc \n",
    "inner join UserCertificationPath ucp on cc.EmploymentJobRoleUUID = UUID_TO_BIN(ucp.EmploymentJobRoleUUID,TRUE) \n",
    "inner join EmploymentJobRole ejr2 on ucp.EmploymentJobRoleUUID = ejr2.EmploymentJobRoleUUID \n",
    "inner join EmploymentJobRoleStatus ejrs on ejr2.EmploymentJobRoleStatusUUID = ejrs.EmploymentJobRoleStatusUUID \n",
    "inner join CertificationPath cp on ucp.CertificationPathUUID = cp.CertificationPathUUID \n",
    "inner join User u on ucp.UserUUID = u.UserUUID \n",
    "left join UserJourneyLevelHistory ujlh on ucp.EmploymentJobRoleUUID = ujlh.UserEntityJobRoleUUID \n",
    "and ujlh.LearnerJourneyLevelUUID = ucp.CurrentLevelUUID \n",
    "and ujlh.IsCurrent = b'1'\n",
    "where ejrs.Name = 'Active'\n",
    "order by u.PIN, cc.TargetLevel '''\n",
    "\n",
    "STR_SQL_CERTIFICATION_SUMMARY = '''select cp.Name as CertPath, u.PIN, ljll.LearnerJourneyLevelTitle, cs.StatusCode  as LJstatus,  \n",
    "ujlh.CompletionDate as DateAchieved, ujlh.LevelExpiryDate as ExpiryDate, CONV(cp.IsTechnical,2,10) as IsTechnical, \n",
    "CONV(ljl.IsFastTrack,2,20) as IsFastTrack,ujlh.UserUUID, ljv.LearnerJourneyVersionUUID \n",
    "from UserJourneyLevelHistory ujlh \n",
    "inner join User u on ujlh.UserUUID = u.UserUUID\n",
    "inner join UserProfile up on u.UserUUID = up.UserUUID \n",
    "inner join LearnerJourneyVersion ljv on ujlh.LearnerJourneyVersionUUID = ljv.LearnerJourneyVersionUUID \n",
    "inner join CourseStatus cs on ujlh.SuccessStatusUUID = cs.CourseStatusUUID \n",
    "inner join LearnerJourneyLevel ljl on ujlh.LearnerJourneyLevelUUID = ljl.LearnerJourneyLevelUUID\n",
    "inner join LearnerJourneyLevelLocal ljll ON ljl.LearnerJourneyLevelUUID = ljll.LearnerJourneyLevelUUID AND ljll.LanguageUUID = (SELECT LanguageUUID FROM Language WHERE LanguageName = 'English')\n",
    "inner join CertificationPath cp on ljv.CertificationPathUUID = cp.CertificationPathUUID \n",
    "where ujlh.IsCurrent = 1\n",
    "order by u.PIN, ujlh.CompletionDate'''\n",
    "\n",
    "#FROM V2E_Views_Data_08\n",
    "STR_SQL_LEARNING_CLASSROOM = '''select cu.PIN, CONV(cuc.IsCurrent,2,10) as IsCurrent, cuc.AssetTypeName, cuc.CourseCode, cuc.CourseTitle, cuc.ClassroomSessionSessionName, cuc.ClassroomSessionStartDate, cuc.ClassroomSessionEndDate, cuc.ClassroomSessionDuration, cuc.Status, cuc.CourseStatusName, cuc.Score, cuc.PreReqScore, cuc.DirScore, cuc.EndTestScore, cuc.OveralScore, cuc.VenueName, cuc.AttempDate, cuc.CompletedDate, cuc.CourseLanguageName, cuc.Version, cuc.ClassroomPreReqCount\n",
    "from Cache_UserClassroom cuc INNER JOIN Cache_User cu ON cuc.UserUUID = cu.UserUUID'''\n",
    "\n",
    "\n",
    "STR_SQL_LEARNING_EXAMS = '''select cu.PIN, CONV(cue.IsCurrent,2,10) as IsCurrent, cue.AssetTypeName, cue.CourseCode, cue.CourseTitle, cue.ClassroomSessionSessionName, \n",
    "cue.ClassroomSessionStartDate, cue.ClassroomSessionEndDate, cue.ClassroomSessionDuration, cue.Status, \n",
    "cue.CourseStatusName, cue.Score, cue.PreReqScore, cue.DirScore, cue.EndTestScore, cue.OveralScore, cue.VenueName, \n",
    "cue.AttempDate, cue.CompletedDate, cue.CourseLanguageName, cue.Version, cue.ClassroomPreReqCount\n",
    "from Cache_UserExam cue \n",
    "INNER JOIN Cache_User cu ON cue.UserUUID = cu.UserUUID'''\n",
    "\n",
    "STR_SQL_LEARNING_ONLINE = '''select cu.PIN, CONV(cuol.IsCurrent,2,10) as IsCurrent, cuol.AssetTypeName, cuol.CourseCode, cuol.CourseTitle, cuol.ClassroomSessionSessionName, cuol.ClassroomSessionStartDate, cuol.ClassroomSessionEndDate, cuol.ClassroomSessionDuration, \n",
    "cuol.Status, cuol.CourseStatusName, cuol.Score, cuol.PreReqScore, cuol.DirScore, cuol.EndTestScore, cuol.OveralScore, cuol.VenueName, \n",
    "cuol.AttempDate, cuol.CompletedDate, cuol.CourseLanguageName, cuol.Version, cuol.ClassroomPreReqCount\n",
    "from Cache_UserOnlineLearning cuol \n",
    "INNER JOIN Cache_User cu ON cuol.UserUUID = cu.UserUUID '''\n",
    "\n",
    "FILE_DEST_BUSINESS_UNITS = 'BusUnits.csv'\n",
    "FILE_DEST_USERS = 'Users.csv'\n",
    "FILE_DEST_EMPLOYMENT = 'Employment.csv'\n",
    "FILE_DEST_EMPLOYMENT_JOB_ROLE = 'EmpJobRole.csv'\n",
    "FILE_DEST_CERTIFICATION_PATH = 'CertPath.csv'\n",
    "FILE_DEST_CERTIFICATION_SUMMARY = 'CertsSummary.csv'\n",
    "FILE_DEST_LEARNING_CLASSROOM = 'ClassroomLearningHistory.csv'\n",
    "FILE_DEST_LEARNING_EXAMS = 'UserExamHistory.csv'\n",
    "FILE_DEST_LEARNING_ONLINE = 'OnlineLearningHistory.csv'\n",
    "FILE_DEST_FASTTRACKS = 'FastTrackUsers.csv'\n",
    "FILE_DEST_JOURNEY_LEVEL_HISTORY = 'TechLevelsHistory.csv'\n",
    "FILE_SRC_FIMS_SPECIALISM = 'Franchise_Specialism_Report.xlsx'\n",
    "FILE_SRC_FIMS_NETWORK = 'Network_Planning_Report.xlsx'\n",
    "\n",
    "\n",
    "DIC_QUERIES_FILES_01 = {STR_SQL_USERS:FILE_DEST_USERS,STR_SQL_EMPLOYMENT:FILE_DEST_EMPLOYMENT,STR_SQL_EMPLOYMENT_JOB_ROLE:FILE_DEST_EMPLOYMENT_JOB_ROLE,STR_SQL_CERIFICATION_PATH:FILE_DEST_CERTIFICATION_PATH,STR_SQL_CERTIFICATION_SUMMARY:FILE_DEST_CERTIFICATION_SUMMARY}\n",
    "DIC_QUERIES_FILES_02 = {STR_SQL_LEARNING_CLASSROOM:FILE_DEST_LEARNING_CLASSROOM,STR_SQL_LEARNING_EXAMS:FILE_DEST_LEARNING_EXAMS,STR_SQL_LEARNING_ONLINE:FILE_DEST_LEARNING_ONLINE}\n",
    "\n",
    "STR_DB_IP_PROD = '99.81.195.113'\n",
    "STR_DB_PORT_PROD = '13306'\n",
    "STR_DB_NAME_PROD = 'JLR_LMS_Reporting'\n",
    "\n",
    "def Username():\n",
    "    return os.getlogin().lower()\n",
    "\n",
    "def DIR_REPOSITORY():\n",
    "    return 'C:\\\\Users\\\\' + Username() + '\\\\OneDrive\\\\JAGUAR LAND ROVER\\\\Network Excellence Reporting & Analytics - NERA Data Repository\\\\'\n",
    "\n",
    "def DIR_EXTRACTS():\n",
    "    return DIR_REPOSITORY() + 'Raw Extracts\\\\'\n",
    "\n",
    "def DIR_RAW_EVO_EXTRACTS():\n",
    "    return DIR_EXTRACTS() + 'EvoReportingDB\\\\'\n",
    "\n",
    "def DIR_FIMS_SPECIALISM_EXTRACTS():\n",
    "    return DIR_EXTRACTS() + 'FIMS - Franchise Specialism Report\\\\'\n",
    "\n",
    "def DIR_FIMS_NETWORK_EXTRACTS():\n",
    "    return DIR_EXTRACTS() + 'FIMS - Network Development Report\\\\'\n",
    "\n",
    "\n",
    "STR_TEMP_FOLDER = 'C:\\\\luigi temp\\\\'\n",
    "# Think this is not needed STR_RSA_PATH = 'C:\\\\Program Files\\\\RSA SecurID Software Token\\\\SecurID.exe'\n",
    "STR_RAPIDMINER_PATH = 'C:\\\\Program Files\\\\RapidMiner\\\\RapidMiner Studio\\\\scripts\\\\rapidminer-batch.bat'\n",
    "STR_NERA_Repository = r'//NERA RapidMiner Repository'\n",
    "STR_RM_SUCCESS_STRING = 'finished successfully after'\n",
    "\n",
    "\n",
    "DB_ENVIRONMENT =  'V2E_Reporting_PROD' #'V2E_Warehouse_UAT' #'V2E_Reporting_UAT' #'V2E_Reporting_PROD'\n",
    "FILE_CREDENTIALS = 'local_configs.json'\n",
    "crdntlspath = os.path.expanduser('C:\\\\Users\\\\' + Username() + '\\\\OneDrive\\\\OneDrive - JAGUAR LAND ROVER\\Documents' + '\\\\' + FILE_CREDENTIALS)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Running Module NERA_BAU_STATIC_DATA_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed May 18 09:11:03 2022\n",
    "\n",
    "@author: MREID7\n",
    "\"\"\"\n",
    "#import os\n",
    "#import re\n",
    "from datetime import datetime\n",
    "#import time\n",
    "import json\n",
    "#import pymysql\n",
    "import pandas as pd\n",
    "import sqlalchemy as sqa\n",
    "from lxml import etree\n",
    "from lxml.objectify import NoneElement\n",
    "import lxml\n",
    "import NERA_BAU_STATIC_DATA_01 as STATIC_DATA\n",
    "\n",
    "print(STATIC_DATA.Username())\n",
    "DATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "\n",
    "USER_DOCS_PATH = 'C:\\\\Users\\\\' + STATIC_DATA.Username() + '\\\\OneDrive\\\\OneDrive - JAGUAR LAND ROVER\\\\Documents'\n",
    "NERA_REPOS_PATH = 'C:\\\\Users\\\\' + STATIC_DATA.Username() + r'\\OneDrive\\JAGUAR LAND ROVER\\Network Excellence Reporting & Analytics - NERA Data Repository'\n",
    "FILE_FIMS_SPEC = NERA_REPOS_PATH + '\\\\Raw Extracts\\\\FIMS - Franchise Specialism Report\\Franchise_Specialism_Report.xlsx'\n",
    "FIL_STATIC = NERA_REPOS_PATH + '\\\\Reference Data\\Business Units\\\\FIMsStaticMapping.json'\n",
    "DIR_RAPIDMINER = NERA_REPOS_PATH + '\\\\Raw Extracts\\\\EvoReportingDB'\n",
    "\n",
    "DB_DESC =  'V2E_Reporting_UAT' #'V2E_Warehouse_UAT' #'V2E_Reporting_UAT' # 'V2E_Reporting_PROD'\n",
    "FILE_CREDENTIALS = 'local_configs.json'\n",
    "\n",
    "def GetDBengine(sKeyDB,sCredsPath,sCredsFile):\n",
    "    #Creates a database connection and SQLAlchemy engine from User Config file\n",
    "    crdntlspath = sCredsPath + '\\\\' + sCredsFile\n",
    "    with open(crdntlspath,'r') as read_crdntls:\n",
    "        crdntls = json.load(read_crdntls)\n",
    "        dbentry = crdntls['logins'][sKeyDB]\n",
    "    connStr = 'mysql+pymysql://' + dbentry['user'] + ':' + dbentry['pass'] + '@' + dbentry['ip'] + ':' + dbentry['port'] + '/' + dbentry['name']\n",
    "    objEngine = sqa.create_engine(connStr)\n",
    "    return objEngine\n",
    "    \n",
    "\n",
    "def GetFIMsAddressIDoverrides():\n",
    "    with open(FIL_STATIC,'r') as objSTATIC:\n",
    "        dicStatic = json.load(objSTATIC)\n",
    "        dicADDRESSID_OVERRIDES = dicStatic['AddressIDmapping']\n",
    "    return dicADDRESSID_OVERRIDES\n",
    "\n",
    "def GetFIMsMarketsOverrides():\n",
    "    with open(FIL_STATIC,'r') as objSTATIC:\n",
    "        dicStatic = json.load(objSTATIC)\n",
    "        dicFIMS_EVO_MKT_MAP = dicStatic['MarketMapping']\n",
    "    return dicFIMS_EVO_MKT_MAP\n",
    "\n",
    "def GetEvoBusinessUnits():\n",
    "    engine = GetDBengine(DB_DESC,USER_DOCS_PATH,FILE_CREDENTIALS)\n",
    "    strSQL = STATIC_DATA.STR_SQL_BUSINESS_UNITS\n",
    "    dfEvo2 = pd.read_sql(strSQL,engine)\n",
    "    dfEvo2['IsRetailer'] = dfEvo2['BusUnitSubType'].map(lambda x: 1 if (('Retailer' in x )|('Sales' in x)|('Independent' in x))else 0)\n",
    "    dfEvo2['FranCICode'] = dfEvo2['CICode'].map(lambda x: x[-5::] if len(x) >4 else x)\n",
    "    dfEvo2['BrandCode'] = dfEvo2['BrandCode'].str[0]\n",
    "    return dfEvo2\n",
    "\n",
    "def GetFIMsBusUnits():\n",
    "    dfFIMSSrc = pd.read_excel(FILE_FIMS_SPEC,sheet_name='Report 1',skiprows=3)\n",
    "    dfFIMSSrc.drop(dfFIMSSrc.columns.difference(['Distributor CI Code','Franchise Country','Franchise CI Code','JLR Number','Franchise Trading Title','Brand','Franchise Status','Franchise Type','Address Postcode','Address Town','Address ID']),axis=1,inplace=True)\n",
    "    dicManualMarkets = GetFIMsMarketsOverrides()\n",
    "    dfFIMSSrc.replace({\"Franchise Country\": dicManualMarkets},inplace=True)\n",
    "    dfFIMSSrc['Brand'] = dfFIMSSrc['Brand'].str[0]\n",
    "    dfFIMSSrc['F_CICode'] = dfFIMSSrc['Distributor CI Code'] + dfFIMSSrc['Franchise CI Code']\n",
    "    dfFIMSSrc['IsRetailer'] = dfFIMSSrc['Franchise Type'].map(lambda x: 1 if (('Retailer' in x )|('Sales' in x)|('Boutique' in x))else 0)\n",
    "    return dfFIMSSrc\n",
    "\n",
    "def GetCombinedFIMsEvo():\n",
    "    dfFIMS = GetFIMsBusUnits()\n",
    "    dfEvo = GetEvoBusinessUnits()\n",
    "    dfMerged01 = dfEvo.merge(dfFIMS, how='left', left_on=['FranCICode','BrandCode','MarketName','IsRetailer'], right_on=['Franchise CI Code','Brand','Franchise Country','IsRetailer'])\n",
    "    dfMerged01['ToRemove'] = dfMerged01.apply(lambda x: 1 if ((x['IsActiveStatus'] ==0 )&(x['Franchise Status'] == 'Terminated'))else 0,axis=1)\n",
    "    dicAddressIDOverrides = GetFIMsAddressIDoverrides()\n",
    "    dfMerged01['AddressID']=dfMerged01.apply(lambda x: dicAddressIDOverrides[x['CICode']]  if x['CICode'] in dicAddressIDOverrides else x['Address ID'] ,axis=1)\n",
    "    #As a final capture - those whose CI Codes are exactly the same but have not yet been mapped (bedcause the Franchise type is different)\n",
    "    dicLastChanceMaps = {}\n",
    "    for indx,row in dfFIMS[dfFIMS['Franchise Status']=='Active'][['F_CICode','Address ID','IsRetailer']].iterrows():\n",
    "        if row['F_CICode'] in dicLastChanceMaps:\n",
    "            if row['IsRetailer'] ==1:\n",
    "                dicLastChanceMaps[row['F_CICode']]=row['Address ID']\n",
    "        else:\n",
    "            dicLastChanceMaps[row['F_CICode']]=row['Address ID']\n",
    "    dfMerged01['AddressID']=dfMerged01.apply(lambda x: dicLastChanceMaps[x['CICode']]  if (pd.isna(x['AddressID'])) & (x['CICode'] in dicLastChanceMaps) else x['AddressID'],axis=1)\n",
    "    return dfMerged01\n",
    "    \n",
    "def BusinessUnitsExtracts():\n",
    "    dfRapidMinerBusinessUnits = GetCombinedFIMsEvo()\n",
    "    dfRapidMinerBusinessUnits.to_csv(DIR_RAPIDMINER + '\\\\BusUnits.csv',index=False)\n",
    "    lstColsToDrop = ['Distributor CI Code','Franchise Country','JLR Number','Brand','Franchise CI Code','Franchise Trading Title','Franchise Type','Address Town','Address Postcode','Address ID','Franchise Status','F_CICode','ToRemove']\n",
    "    dfGCPbusinessUnits = dfRapidMinerBusinessUnits.drop(labels=lstColsToDrop,axis=1)\n",
    "    dfGCPbusinessUnits.to_csv(DIR_RAPIDMINER + '\\\\BusUnitsGCP.csv',index=False)\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print('Running Module NERA_BAU_EXTRACTS_BUS_UNITS_01 at ' + datetime.now().strftime('%H:%M:%S'))\n",
    "    BusinessUnitsExtracts()\n",
    "    print('Finished NERA_BAU_EXTRACTS_BUS_UNITS_01 at ' + datetime.now().strftime('%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Sep  7 09:20:10 2022\n",
    "\n",
    "@author: MREID7\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlalchemy as sqa\n",
    "from lxml import etree\n",
    "from datetime import datetime\n",
    "#from lxml.objectify import NoneElement\n",
    "#import lxml\n",
    "import NERA_BAU_STATIC_DATA_01 as STATIC_DATA\n",
    "\n",
    "print(STATIC_DATA.Username())\n",
    "DATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "\n",
    "USER_DOCS_PATH = 'C:\\\\Users\\\\' + STATIC_DATA.Username() + '\\\\OneDrive\\\\OneDrive - JAGUAR LAND ROVER\\\\Documents'\n",
    "NERA_REPOS_PATH = 'C:\\\\Users\\\\' + STATIC_DATA.Username() + r'\\OneDrive\\JAGUAR LAND ROVER\\Network Excellence Reporting & Analytics - NERA Data Repository'\n",
    "FILE_FIMS_SPEC = NERA_REPOS_PATH + '\\\\Raw Extracts\\\\FIMS - Franchise Specialism Report\\Franchise_Specialism_Report.xlsx'\n",
    "FIL_STATIC = NERA_REPOS_PATH + '\\\\Reference Data\\Business Units\\\\FIMsStaticMapping.json'\n",
    "DIR_RAPIDMINER = NERA_REPOS_PATH + '\\\\Raw Extracts\\\\EvoReportingDB'\n",
    "\n",
    "DIR_TEST_REPOSITORY ='C:\\\\temp\\\\'\n",
    "#FILE_MKT_GRP = 'tblMarketGroup.csv'\n",
    "#FILE_MKTS = 'tblMarket.csv'\n",
    "#FILE_BUTMMG ='tblBusinessUnitToMarketOrMarketGroup.csv'\n",
    "FILE_BUS_UNITS = 'BusUnits.csv'\n",
    "\n",
    "DB_DESC = 'V2E_Reporting_UAT' #'V2E_Warehouse_UAT' #'V2E_Reporting_UAT' #'V2E_Reporting_PROD'\n",
    "FILE_CREDENTIALS = 'local_configs.json'\n",
    "\n",
    "def GetDBengine(sKeyDB,sCredsPath,sCredsFile):\n",
    "    #Creates a database connection and SQLAlchemy engine from User Config file\n",
    "    crdntlspath = sCredsPath + '\\\\' + sCredsFile\n",
    "    print(crdntlspath)\n",
    "    with open(crdntlspath,'r') as read_crdntls:\n",
    "        crdntls = json.load(read_crdntls)\n",
    "        dbentry = crdntls['logins'][sKeyDB]\n",
    "    connStr = 'mysql+pymysql://' + dbentry['user'] + ':' + dbentry['pass'] + '@' + dbentry['ip'] + ':' + dbentry['port'] + '/' + dbentry['name']\n",
    "    objEngine = sqa.create_engine(connStr)\n",
    "    return objEngine\n",
    "\n",
    "#Map Users to Market\n",
    "def UsersToMarketMap():\n",
    "    engine = GetDBengine(DB_DESC,USER_DOCS_PATH,FILE_CREDENTIALS)\n",
    "    strDirData = STATIC_DATA.DIR_RAW_EVO_EXTRACTS()\n",
    "    strSQL = STATIC_DATA.STR_SQL_USERS_TO_MKT_MKTGRP\n",
    "    dfExtract = pd.read_sql(strSQL,engine)\n",
    "    dfExtract.to_csv(strDirData + '\\\\' + 'UsersToMarketMap.csv',index=False)\n",
    "\n",
    "#Market Groups\n",
    "\n",
    "class BusinessUnit:\n",
    "    def __init__(self,strUUID):\n",
    "        self.Name = ''\n",
    "        self.UUID = strUUID\n",
    "        self.CICode = ''\n",
    "        self.FranchiseType = ''\n",
    "\n",
    "class Market:\n",
    "    def __init__(self,strUUID,strName):\n",
    "        self.Name = strName\n",
    "        self.UUID = strUUID\n",
    "        self.BusinessUnits = {}\n",
    "            \n",
    "    def AddNewBusinessUnit(self, strUUID, objBU):\n",
    "        if strUUID not in self.BusinessUnits:\n",
    "            #print('Adding BusUnit')\n",
    "            self.BusinessUnits[strUUID] = objBU\n",
    "        \n",
    "    def GenerateXmlMarketElement(self):\n",
    "        lmRoot = etree.Element('itm', level='m', uuid=self.UUID , nm=self.Name)\n",
    "        if len(self.BusinessUnits)>0:\n",
    "            #print('Market has Bus Units')\n",
    "            lmChildren = etree.Element('itms')\n",
    "            for sBU in self.BusinessUnits:\n",
    "                oBU = self.BusinessUnits[sBU]\n",
    "                lmBU = etree.Element('itm', level='b', uuid=sBU , nm=oBU.Name)\n",
    "                lmChildren.append(lmBU)\n",
    "            lmRoot.append(lmChildren)\n",
    "        return lmRoot\n",
    "    \n",
    "class MarketGroup(Market):\n",
    "    def __init__(self,strUUID,strName):\n",
    "        Market.__init__(self,strUUID,strName)\n",
    "        self.SubGroups = {}\n",
    "        self.Markets = {}\n",
    "\n",
    "        \n",
    "    def AddNewSubGroup(self, strUUID, objMktGrp):\n",
    "        if strUUID not in self.SubGroups:\n",
    "            self.SubGroups[strUUID] = objMktGrp\n",
    "\n",
    "    def AddNewMarket(self, strUUID, objMarket):\n",
    "        if strUUID not in self.Markets:\n",
    "            self.Markets[strUUID] = objMarket\n",
    "            \n",
    "    def GenerateXmlMarketGroupElement(self):\n",
    "        lmRoot = etree.Element('itm', level='mg', uuid=self.UUID , nm=self.Name)\n",
    "        if len(self.BusinessUnits)>0 or len(self.Users)>0 or len(self.SubGroups)>0 or len(self.Markets)>0:\n",
    "            lmChildren = etree.Element('itms')\n",
    "            for sSG in self.SubGroups:\n",
    "                oSG = self.SubGroups[sSG]\n",
    "                lmSG = oSG.GenerateXmlMarketGroupElement()\n",
    "                lmChildren.append(lmSG)\n",
    "            for sM in self.Markets:\n",
    "                oM = self.Markets[sM]\n",
    "                lmM = oM.GenerateXmlMarketElement()\n",
    "                lmChildren.append(lmM)\n",
    "            for sBU in self.BusinessUnits:\n",
    "                oBU = self.BusinessUnits[sBU]\n",
    "                lmBU = etree.Element('itm', level='b', uuid=sBU , nm=oBU.Name)\n",
    "                lmChildren.append(lmBU) \n",
    "            lmRoot.append(lmChildren)\n",
    "        return lmRoot\n",
    "    \n",
    "def GroupTree01(uuid, name,dfMktGrps,dfMkts,dfMktMap,dicMktBUs):\n",
    "    #print('Name: ' + name)\n",
    "    objMG = MarketGroup(uuid,name)\n",
    "    if uuid in dicMktBUs:\n",
    "        for sBU in dicMktBUs[uuid]:\n",
    "            objMG.AddNewBusinessUnit(sBU,dicMktBUs[uuid][sBU])\n",
    "    for tupMkt in dfMkts[dfMkts['MarketGroupUUID']==uuid].itertuples():\n",
    "        oMkt = Market(tupMkt.MarketUUID,tupMkt.MarketName)  \n",
    "        if tupMkt.MarketUUID in dicMktBUs:\n",
    "            for sBU in dicMktBUs[tupMkt.MarketUUID]:\n",
    "                oMkt.AddNewBusinessUnit(sBU,dicMktBUs[tupMkt.MarketUUID][sBU])\n",
    "        objMG.AddNewMarket(tupMkt.MarketUUID,oMkt)\n",
    "    for tupMG in dfMktGrps[dfMktGrps['ParentMarketGroupUUID']==uuid].itertuples():\n",
    "        oChild = GroupTree01(tupMG.MarketGroupUUID,tupMG.MarketGroupName,dfMktGrps,dfMkts,dfMktMap,dicMktBUs)\n",
    "        objMG.AddNewSubGroup(tupMG.MarketGroupUUID, oChild)\n",
    "    return objMG\n",
    "\n",
    "def BuildXmlDoc01(objBase, lm):\n",
    "    lmChild = etree.Element('mg', uuid=objBase.UUID, nm=objBase.Name)\n",
    "    for sBU in objBase.BusinessUnits:\n",
    "        #print('In MktGrp {0}, {1} add BU: {2}'.format(objBase.UUID,objBase.Name,sBU))\n",
    "        objBU = objBase.BusinessUnits[sBU] \n",
    "        #print(' - BU: {0}, {1}, {2}, {3}'.format(objBU.UUID,objBU.Name, objBU.CICode,objBU.FranchiseType))\n",
    "        lmBU = etree.Element('bu', uuid=str(objBU.UUID), nm=str(objBU.Name), ci=str(objBU.CICode),ftyp=str(objBU.FranchiseType) )\n",
    "        lmChild.append(lmBU)\n",
    "    if len(objBase.Markets)>0:\n",
    "        lmMkts = etree.Element('mkts')\n",
    "        lmChild.append(lmMkts)\n",
    "        for sMkt in objBase.Markets:\n",
    "            objMkt = objBase.Markets[sMkt]\n",
    "            lmMkt = etree.Element('mkt', uuid=objMkt.UUID, nm=objMkt.Name)\n",
    "            for sBU in objMkt.BusinessUnits:\n",
    "                #print('In Mkt add BU: {0}'.format(sBU))\n",
    "                objBU = objMkt.BusinessUnits[sBU] \n",
    "                #print('..adding...uuid: {0} ... Name: {1}, CIcode {2}, {3}'.format(objBU.UUID,objBU.Name, objBU.CICode,objBU.FranchiseType))\n",
    "                lmBU = etree.Element('bu', uuid=objBU.UUID, nm=objBU.Name, ci=objBU.CICode, ftyp=objBU.FranchiseType)\n",
    "                lmMkt.append(lmBU)\n",
    "            lmMkts.append(lmMkt)\n",
    "        lmChild.append(lmMkts)\n",
    "    lm.append(lmChild)\n",
    "    if len(objBase.SubGroups)>0:\n",
    "        lmMgs = etree.Element('mgs')\n",
    "        lmChild.append(lmMgs)\n",
    "        for sSubG in objBase.SubGroups:\n",
    "            objSubG=objBase.SubGroups[sSubG]\n",
    "            BuildXmlDoc01(objSubG,lmMgs)\n",
    "    \n",
    "\n",
    "\n",
    "def MarketGroups(lmUnit,iListLength): \n",
    "    nlMktGrps = lmUnit.xpath(\"ancestor::mg\")\n",
    "    #print(len(nlMktGrps))\n",
    "    strTopLevelName = nlMktGrps[0].attrib['nm']\n",
    "    strTopLevelUUID = nlMktGrps[0].attrib['uuid']\n",
    "    if len(nlMktGrps) < (iListLength + 1):\n",
    "        lstUnits = [strTopLevelName] * (iListLength - len(nlMktGrps) - 1)\n",
    "        lstUUIDs = [strTopLevelUUID] * (iListLength - len(nlMktGrps) - 1)\n",
    "    else:\n",
    "        lstUnits = []\n",
    "        lstUUIDs = []\n",
    "    for lmMG in nlMktGrps:\n",
    "        #print(lmMG.attrib['nm'])\n",
    "        lstUnits.append(lmMG.attrib['nm'])\n",
    "        lstUUIDs.append(lmMG.attrib['uuid'])\n",
    "    lstUnits.append(lmUnit.attrib['nm'])\n",
    "    lstUUIDs.append(lmUnit.attrib['uuid'])\n",
    "    #print(lstUnits)\n",
    "    return lstUnits + lstUUIDs\n",
    "\n",
    "\n",
    "\n",
    "def MarketGroupsXml():\n",
    "    engine = GetDBengine(DB_DESC,USER_DOCS_PATH,FILE_CREDENTIALS)\n",
    "    dfMtkGrp = pd.read_sql(\"SELECT MarketGroupUUID,MarketGroupName,ParentMarketGroupUUID,Level,MarketGroupStatusUUID,IsBusinessRegion FROM MarketGroup WHERE MarketGroupName NOT IN ('Historical Field Teams','ETL Test','Test Market Group','Historical Global Trainers','Historical JLRE')\",engine)\n",
    "    dfMarkets = pd.read_sql('SELECT MarketUUID,BusinessRegionUUID,MarketGroupUUID,MarketName,CONV(IsActive,2,10) as IsActive,MarketStatusUUID, CONV(IsTestMarket,2,10) as IsTestMarket FROM Market',engine)\n",
    "    dfBUTMMG = pd.read_sql('SELECT BusinessUnitToMarketOrMarketGroupUUID,BusinessUnitUUID,MarketOrMarketGroupUUID FROM BusinessUnitToMarketOrMarketGroup',engine)\n",
    "    dfBusUnits = pd.read_csv(DIR_RAPIDMINER + '\\\\' + FILE_BUS_UNITS)\n",
    "    dfBusUnits.fillna('',inplace=True)\n",
    "    dicMktBUs = {}\n",
    "    for mktUUID in dfBUTMMG['MarketOrMarketGroupUUID'].unique():\n",
    "        dicBUs = {}\n",
    "        for tupBU in dfBUTMMG[dfBUTMMG['MarketOrMarketGroupUUID']==mktUUID].itertuples():\n",
    "            oBU = BusinessUnit(tupBU.BusinessUnitUUID)\n",
    "            dfTmpBU = dfBusUnits[dfBusUnits['BusinessUnitUUID']==tupBU.BusinessUnitUUID].reset_index()\n",
    "            if len(dfTmpBU.index)>0:\n",
    "                oBU.Name = dfTmpBU.loc[0,'BusinessUnit']\n",
    "                oBU.CICode = dfTmpBU.loc[0,'CICode']\n",
    "                oBU.FranchiseType = dfTmpBU.loc[0,'BusUnitSubType']\n",
    "            dicBUs[tupBU.BusinessUnitUUID] = oBU\n",
    "        dicMktBUs[mktUUID]=dicBUs\n",
    "    dfGlobal = dfMtkGrp[dfMtkGrp['ParentMarketGroupUUID'].isnull()].iloc[0]\n",
    "    objGlobal = GroupTree01(dfGlobal['MarketGroupUUID'],dfGlobal['MarketGroupName'],dfMtkGrp,dfMarkets,dfBUTMMG,dicMktBUs)\n",
    "    lmRoot = etree.Element('root')\n",
    "    lmTopLevel = etree.Element('mgs')\n",
    "    lmRoot.append(lmTopLevel)\n",
    "    BuildXmlDoc01(objGlobal,lmTopLevel)\n",
    "    return etree.ElementTree(lmRoot)\n",
    "\n",
    "def MarketGroupsXmlToFlat():\n",
    "    INT_MAX_LEVEL = 5\n",
    "    tree = MarketGroupsXml()\n",
    "    nlMkts = tree.findall(\".//mkt\")\n",
    "    lstData = []\n",
    "    for lmMkt in nlMkts:\n",
    "        lstFull = MarketGroups(lmMkt,INT_MAX_LEVEL)\n",
    "        lstData.append(lstFull)\n",
    "    dfMKtGrps = pd.DataFrame(lstData)\n",
    "    dfMKtGrps.to_csv(DIR_RAPIDMINER + '\\\\MarketGroups.csv',index=False)\n",
    "    #dfMKtGrps.to_csv('C:\\\\temp\\\\MarketGroups.csv',index=False)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print('Running Module NERA_BAU_EXTRACTS_REGIONS_01 at ' + datetime.now().strftime('%H:%M:%S'))\n",
    "    MarketGroupsXmlToFlat()\n",
    "    print('Completed Market Groups, now UsersToMarketMap at ' + datetime.now().strftime('%H:%M:%S'))\n",
    "    UsersToMarketMap()\n",
    "    print('Finished NERA_BAU_EXTRACTS_REGIONS_01 at ' + datetime.now().strftime('%H:%M:%S'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = \"myname is a Idris Adebisi.I am destined to be successful in life and I am working towards that..may God continue to guide and direct me and keep my family alive and make them enjoy thier time on earth..may God also forgive all my sins and make me achaive everything i am for including my wife and my siblings and parents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"\"\"Mr. Michael\n",
    "            Mr Smith\n",
    "            Ms Kritika\n",
    "            Mrs. T\n",
    "            Ms. Leena\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = re.compile(r'\\w+\\.?\\W\\w+')\n",
    "m = re.compile(r'Mr.?\\W\\w+')\n",
    "f = re.compile(r'Mr?s.?\\W\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = re.compile(r'\\w+\\.?\\w+@\\w+.\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(0, 11), match='Mr. Michael'>,\n",
       " <re.Match object; span=(24, 32), match='Mr Smith'>,\n",
       " <re.Match object; span=(45, 55), match='Ms Kritika'>,\n",
       " <re.Match object; span=(68, 74), match='Mrs. T'>,\n",
       " <re.Match object; span=(87, 96), match='Ms. Leena'>]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.finditer(email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "def trace(root):\n",
    "    nodes, edges = set(), set()\n",
    "    def build(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for child in v._downstream:\n",
    "                edges.add((child, v))\n",
    "                build(child)\n",
    "    build(root)\n",
    "    return nodes, edges\n",
    "\n",
    "def draw_dot(root, format='svg', rankdir='LR'):\n",
    "    \"\"\"\n",
    "    format: png | svg | ...\n",
    "    rankdir: TB (top to bottom graph) | LR (left to right)\n",
    "    \"\"\"\n",
    "    assert rankdir in ['LR', 'TB']\n",
    "    nodes, edges = trace(root)\n",
    "    dot = Digraph(format=format, graph_attr={'rankdir': rankdir}) #, node_attr={'rankdir': 'TB'})\n",
    "    \n",
    "    for n in nodes:\n",
    "        dot.node(name=str(id(n)), label = \"{ data %.4f | grad %.4f }\" % (n.data, n.grad), shape='record')\n",
    "        if n._op:\n",
    "            dot.node(name=str(id(n)) + n._op, label=n._op)\n",
    "            dot.edge(str(id(n)) + n._op, str(id(n)))\n",
    "    for n1, n2 in edges:\n",
    "        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Tensor:\n",
    "    __allnodes = []\n",
    "    def __init__(self, data, _downstream=(), _op='', dtype=None):\n",
    "        assert isinstance(data , (int,float)), \"data must be of type int or float\"\n",
    "        self.data = float(data) if not dtype else dtype(data)\n",
    "        self._downstream = _downstream\n",
    "        self._backward = lambda: None\n",
    "        self._op = _op\n",
    "        self.grad = 0.0\n",
    "\n",
    "    def __add__(self, other):\n",
    "       other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "       out =  Tensor(data =(self.data + other.data), _downstream=(self,other), _op= '+')\n",
    "       def _backward():\n",
    "          self.grad += 1.0 * out.grad\n",
    "          other.grad += 1.0 * out.grad\n",
    "       out._backward = _backward\n",
    "       return out  \n",
    "\n",
    "    def __mul__(self, other):\n",
    "       other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "       out =  Tensor(data =(self.data * other.data), _downstream=(self,other), _op= '*') \n",
    "       def _backward():\n",
    "         self.grad += other.data * out.grad\n",
    "         other.grad += self.data * out.grad\n",
    "       out._backward = _backward\n",
    "       return out \n",
    "    \n",
    "    def __pow__(self, other):\n",
    "       other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "       out = Tensor(data = (self.data**other.data), _downstream=(self,), _op='pow')\n",
    "       def _backward():\n",
    "         self.grad += (other.data) * (self.data ** (other.data -1)) * out.grad\n",
    "         other.grad += (self.data) * (other.data ** (self.data -1)) * out.grad\n",
    "       out._backward = _backward\n",
    "       return out\n",
    "    \n",
    "    def relu(self):\n",
    "        out = Tensor(data=(0 if self.data < 0 else self.data), _downstream=(self,), _op='relu')\n",
    "        def _backward():\n",
    "            self.grad += out.data * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    @classmethod\n",
    "    def tanh(self):\n",
    "        t = ((2*self).exp() -1) / ((2*self).exp()+ 1)\n",
    "        out = Tensor(data=(t.data), _downstream=(self, ),  _op='tanh')\n",
    "        def _backward():\n",
    "            self.grad += (1 - t.data**2) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "       \n",
    "    def sigmoid(self):\n",
    "        x = 1 / (1 + -self.exp())\n",
    "        out = Tensor(data=(x.data), _downstream=(self, ),  _op='sigmoid')\n",
    "        def _backward():\n",
    "            self.grad = None\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def exp(self):\n",
    "        x = self.data\n",
    "        out = Tensor(data=(np.exp(x)), _downstream=(self, ), _op='exp')\n",
    "        def _backward():\n",
    "            self.grad += out.data * out.grad\n",
    "        out._backward = _backward        \n",
    "        return out   \n",
    "       \n",
    "    def backward(self):\n",
    "       nodes = self.__allnodes()\n",
    "       self.grad = 1\n",
    "       for node in nodes:\n",
    "         node._backward()\n",
    "   \n",
    "    def zero_grad(self):\n",
    "       nodes = self.__allnodes()\n",
    "       for node in nodes:\n",
    "         node.grad = 0\n",
    "    \n",
    "    def __allnodes(self):\n",
    "       nodes = []\n",
    "       def get_downstream(object, visited = set()):\n",
    "         if object not in visited:\n",
    "            visited.add(object)\n",
    "            nodes.append(object)\n",
    "            for children in object._downstream:\n",
    "               get_downstream(children)\n",
    "       get_downstream(self)\n",
    "       return nodes \n",
    "    \n",
    "    def __neg__(self): \n",
    "       return self * -1\n",
    "\n",
    "    def __radd__(self, other):\n",
    "       return self + other\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "       return self * (other**-1)\n",
    "    \n",
    "    def __rmul__(self,other):\n",
    "       return self * other\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "      return self + (-other)\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "       return self * (other**-1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "      return f\"Tensor(data= {self.data}, grad={self.grad})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, inx):\n",
    "        \"\"\"\"\n",
    "        inx: number of input to the neuron\n",
    "        \"\"\"\n",
    "        self.weight = [Tensor(np.random.normal()) for _ in range(inx)]\n",
    "        self.bias = Tensor(np.random.normal())\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        out = sum((x*w for x,w in zip(x,self.weight))) + self.bias\n",
    "        # out = out.relu()\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.weight + [self.bias]\n",
    "\n",
    "class LinearLayer:\n",
    "    def __init__(self, inx, out):\n",
    "        \"\"\"\"\n",
    "        inx: number of neuron input in the input layer\n",
    "        out: number of neurons in the layer\n",
    "        \"\"\"\n",
    "        self.neurons = [Neuron(inx) for _ in range(out)]       \n",
    "    def __call__(self, x):\n",
    "        out = [n(x) for n in self.neurons]\n",
    "        return out[0] if len(out) < 2 else out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters() ]\n",
    "    \n",
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "    \n",
    "\n",
    "from abc import abstractmethod, ABCMeta\n",
    "class Model(metaclass=ABCMeta):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self,*args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def parameters(self):\n",
    "        layers = self._layers()\n",
    "        parameters = [p for layer in layers for p in layer.parameters()]\n",
    "        return parameters\n",
    "\n",
    "    def _layers(self):\n",
    "        layers = []\n",
    "        for _, layer in  self.__dict__.items():\n",
    "            if isinstance(layer, (LinearLayer,)):\n",
    "                layers.append(layer)\n",
    "        return layers\n",
    "\n",
    "    def summary(self):\n",
    "        layers = self._layers()\n",
    "\n",
    "\n",
    "class MLP(Model):\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.layer = LinearLayer(3,4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    @classmethod\n",
    "    def tanh(cls,x):\n",
    "        out = ((2*x).exp() -1) / ((2*x).exp()+ 1)\n",
    "        return out\n",
    "    \n",
    "    @classmethod    \n",
    "    def sigmoid(cls, x):\n",
    "        out = 1 / (1 + -x.exp())\n",
    "        return out  \n",
    "\n",
    "class Loss:\n",
    "    @classmethod\n",
    "    def bianaryentropy(cls, ytrue, ypred):\n",
    "        loss = (-ytrue * np.log(ypred)) + ((1-ytrue)*np.log(1-ypred))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Tensor(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Activation.tanh(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data= 0.9999092042625952, grad=0.0)"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = w._layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer\n",
      "<__main__.LinearLayer object at 0x000002B517EEDE88>\n"
     ]
    }
   ],
   "source": [
    "for w , v in w.__dict__.items():\n",
    "    print(w)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(self):\n",
    "    t = ((2*self).exp() -1) / ((2*self).exp()+ 1)\n",
    "    out = Tensor(data=(t.data), _downstream=(self, ),  _op='tanh')\n",
    "    def _backward():\n",
    "        self.grad += (1 - t.data**2) * out.grad\n",
    "    out._backward = _backward\n",
    "    return out\n",
    "    \n",
    "def sigmoid(self):\n",
    "    x = 1 / (1 + -self.exp())\n",
    "    out = Tensor(data=(x.data), _downstream=(self, ),  _op='sigmoid')\n",
    "    def _backward():\n",
    "        self.grad = None\n",
    "    out._backward = _backward\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([LinearLayer(3,4), LinearLayer(4,4), LinearLayer(4,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    ypred = [model(x) for x in xs]\n",
    "    loss = sum((yhat-y)**2 for yhat,y in zip(ypred,ys)) / len(ypred)\n",
    "    if i in range(0,500,25):\n",
    "        print(f'Iteration:{i} ---> {loss.data:}')\n",
    "    lr = 0.01\n",
    "    loss.zero_grad()\n",
    "    loss.backward()\n",
    "    for p in model.parameters():\n",
    "        p.data += -(lr * p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.6931471805599453,\n",
       " 0.6931471805599453,\n",
       " 0.6931471805599453,\n",
       " 0.6931471805599453,\n",
       " -0.6931471805599453,\n",
       " -0.6931471805599453,\n",
       " -0.6931471805599453,\n",
       " -0.6931471805599453]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Tensor:\n",
    "    \"\"\"\n",
    "    A class representing a tensor with a single numerical value.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : int or float\n",
    "        The numerical value of the tensor.\n",
    "    _downstream : tuple of Tensors, optional\n",
    "        Tensors that depend on this tensor. Defaults to an empty tuple.\n",
    "    _op : str, optional\n",
    "        The operation performed on this tensor. Defaults to an empty string.\n",
    "    dtype : type, optional\n",
    "        The data type of the tensor. Defaults to None.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    data : float\n",
    "        The numerical value of the tensor.\n",
    "    grad : float\n",
    "        The gradient of the tensor with respect to the loss.\n",
    "    _downstream : tuple of Tensors\n",
    "        Tensors that depend on this tensor.\n",
    "    _op : str\n",
    "        The operation performed on this tensor.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    __init__(self, data, _downstream=(), _op='', dtype=None):\n",
    "        Initializes a new instance of the Tensor class.\n",
    "    __add__(self, other):\n",
    "        Computes the sum of two tensors.\n",
    "    __mul__(self, other):\n",
    "        Computes the element-wise multiplication of two tensors.\n",
    "    __pow__(self, other):\n",
    "        Computes the element-wise power of a tensor.\n",
    "    relu(self):\n",
    "        Computes the Rectified Linear Unit (ReLU) activation function of a tensor.\n",
    "    tanh(self):\n",
    "        Computes the hyperbolic tangent (tanh) activation function of a tensor.\n",
    "    sigmoid(self):\n",
    "        Computes the sigmoid activation function of a tensor.\n",
    "    exp(self):\n",
    "        Computes the exponential function of a tensor.\n",
    "    backward(self):\n",
    "        Computes the gradient of all the tensors in the computational graph with respect to some scalar loss function.\n",
    "    zero_grad(self):\n",
    "        Sets the gradient of all the tensors in the computational graph to zero.\n",
    "    __allnodes(self):\n",
    "        Returns a list of all the tensors in the computational graph.\n",
    "    __neg__(self):\n",
    "        Computes the negative value of a tensor.\n",
    "    __radd__(self, other):\n",
    "        Computes the sum of a tensor and a scalar value.\n",
    "    __truediv__(self, other):\n",
    "        Computes the element-wise division of two tensors.\n",
    "    __rmul__(self,other):\n",
    "        Computes the element-wise multiplication of a tensor and a scalar value.\n",
    "    __sub__(self, other):\n",
    "        Computes the difference between two tensors.\n",
    "    __rtruediv__(self, other):\n",
    "        Computes the element-wise division of a scalar value and a tensor.\n",
    "    __repr__(self):\n",
    "        Returns a string representation of the tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, _downstream=(), _op='', dtype=None):\n",
    "        \"\"\"\n",
    "        Initialize a Tensor object.\n",
    "        Parameters:\n",
    "            data (int or float): The numerical value of the tensor.\n",
    "            _downstream (tuple, optional): A tuple of downstream tensors.\n",
    "            _op (str, optional): The operation that produced this tensor.\n",
    "            dtype (type, optional): The desired data type of the tensor.\n",
    "        Raises:\n",
    "            AssertionError: If `data` is not of type `int` or `float`.\n",
    "        \"\"\"\n",
    "        assert isinstance(data , (int,float)), \"data must be of type int or float\"\n",
    "        self.data = float(data) if not dtype else dtype(data)\n",
    "        self._downstream = _downstream\n",
    "        self._op = _op\n",
    "        self.grad = 0.0\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Return a string representation of the Tensor object.\n",
    "        \"\"\"\n",
    "        return f\"Tensor({self.data})\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"\n",
    "        Return the sum of this tensor and another tensor or numerical value.\n",
    "        Parameters:\n",
    "            other (Tensor or int or float): The other tensor or numerical value to add.\n",
    "        Returns:\n",
    "            Tensor: A new tensor representing the sum of this tensor and `other`.\n",
    "        \"\"\"\n",
    "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "        out =  Tensor(data =(self.data + other.data), _downstream=(self,other), _op= '+')   \n",
    "        return out  \n",
    "\n",
    "    def __mul__(self, other):\n",
    "        \"\"\"\n",
    "        Return the product of this tensor and another tensor or numerical value.\n",
    "        Parameters:\n",
    "            other (Tensor or int or float): The other tensor or numerical value to multiply.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: A new tensor representing the product of this tensor and `other`.\n",
    "        \"\"\"\n",
    "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "        out =  Tensor(data =(self.data * other.data), _downstream=(self,other), _op= '*') \n",
    "        return out \n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        \"\"\"\n",
    "        Return this tensor raised to the power of another numerical value.\n",
    "\n",
    "        Parameters:\n",
    "            other (int or float): The numerical value to raise this tensor to the power of.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: A new tensor representing this tensor raised to the power of `other`.\n",
    "        \"\"\"\n",
    "        out = Tensor(data = (self.data**other), _downstream=(self,), _op='pow')\n",
    "        return out\n",
    "    \n",
    "    def relu(self):\n",
    "        \"\"\"\n",
    "        Return the Rectified Linear Unit (ReLU) of this tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: A new tensor representing the ReLU of this tensor.\n",
    "        \"\"\"\n",
    "        x = self.data\n",
    "        out = Tensor(0, (self,), 'relu') if x < 0 else x\n",
    "        return out\n",
    "    \n",
    "    def tanh(self):\n",
    "        \"\"\"\n",
    "        Return the hyperbolic tangent (tanh) of this tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: A new tensor representing the hyperbolic tangent of this tensor.\n",
    "        \"\"\"\n",
    "        t = ((2*self).exp() -1) / ((2*self).exp()+ 1)\n",
    "        out = Tensor(t.data, (self, ), 'tanh')\n",
    "        return out\n",
    "       \n",
    "    def sigmoid(self):\n",
    "        \"\"\"\n",
    "        Return the sigmoid function of this tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: A new tensor representing the sigmoid function of this tensor.\n",
    "        \"\"\"\n",
    "        x = 1 / (1 + -self.exp())\n",
    "        out = Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
